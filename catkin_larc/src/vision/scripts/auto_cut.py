# -*- coding: utf-8 -*-
"""YOLO_SAM_autolabel_multiple.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v1iu8aQ-F8uVBcj8-fXuRE6_s1urObMa
"""
# Commented out IPython magic to ensure Python compatibility.
# %cd segment-anything/notebooks
import os
import torch
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np
import imutils
from pathlib import Path

def remove_background_biggest_contour(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Canny edge detection
    canny = cv2.Canny(gray, 50, 150)

    # Dilate the edges to close gaps
    canny = cv2.dilate(canny, None, iterations=1)
    
    #cv2.imshow('canny', canny) 

    # Find contours in the Canny image
    contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if len(contours) > 0:
        # Find the largest contour by area
        largest_contour = max(contours, key=cv2.contourArea)

        # Create an empty mask
        mask = np.zeros_like(gray)

        # Draw the largest contour on the mask
        cv2.drawContours(mask, [largest_contour], 0, (255), thickness=cv2.FILLED)

        # Use the mask to extract the region of interest (ROI) from the original image
        result = cv2.bitwise_and(image, image, mask=mask)
        #result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)
        #result[:, :, 3] = mask


        return result

    else:
        # If no contours are found, return the original image
        return image


def remove_green_background(image):
    # Convert BGR to HSV
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    

    # define range of cube color in HSV
    lower_green = np.array([0, 0, 0])
    upper_green = np.array([179, 130, 255])

    # define range of green color in HSV

    # lower_green = np.array([0, 0, 0])
    # upper_green = np.array([125, 90, 255])

    # Threshold the HSV image to get only green colors
    mask = cv2.inRange(hsv, lower_green, upper_green)

    #reverse mask to get green letters
    mask = cv2.bitwise_not(mask)
    
    #cv2.imshow('mask', mask)

    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(image, image, mask=mask)

    #res = image.copy()  
    res = np.zeros_like(image, dtype=np.uint8)
    res[mask != 255] = image[mask != 255]
    #res = cv2.cvtColor(res, cv2.COLOR_BGR2BGRA)
    #res[:, :, 3] = mask

    return res

def find_extreme_points(img):
    # Carga la imagen en escala de grises
    image = img #cv2.imread(image_path, 0)
    
    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Encuentra los contornos en la imagen
    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Asegúrate de que se encontraron contornos
    if len(contours) == 0:
        print("No se encontraron contornos en la imagen.")
        return None

    # Encuentra el contorno más grande (puede haber varios contornos)
    largest_contour = max(contours, key=cv2.contourArea)

    # Encuentra los puntos extremos del contorno más grande
    leftmost = tuple(largest_contour[largest_contour[:, :, 0].argmin()][0])
    rightmost = tuple(largest_contour[largest_contour[:, :, 0].argmax()][0])
    topmost = tuple(largest_contour[largest_contour[:, :, 1].argmin()][0])
    bottommost = tuple(largest_contour[largest_contour[:, :, 1].argmax()][0])

    return topmost, rightmost, bottommost, leftmost

pathtoimage = "/home/jabv/Desktop/Dataset_final_yolo_resize_png/A"
resultspath = "/home/jabv/Desktop/DS_letras_se/A"
if not os.path.exists(resultspath):
  os.makedirs(resultspath)
cutobject = "soap"
print("Will be checking images in: ", pathtoimage)
# Model
#model = torch.hub.load("ultralytics/yolov5", "yolov5l")  # or yolov5n - yolov5x6, custom
#model = torch.hub.load("ultralytics/yolov5", 'custom', "yolo11classes.pt", force_reload=True)

import sys
sys.path.append("..")
from segment_anything import sam_model_registry, SamPredictor
sam_model = "h"

#wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
if sam_model =="h":
  sam_checkpoint = "sam_vit_h_4b8939.pth"
  model_type = "vit_h"
else:
  sam_checkpoint = "sam_vit_l_0b3195.pth"
  model_type = "vit_l"

device = "cuda"

sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)

predictor = SamPredictor(sam)

# Creating annotation in COCO format
#{"id": 0, "file_name": "0.jpg", "height": 480, "width": 736}
#images=[]
#annotations=[]
#categories=[]

#image_0 ={"id": 0, "file_name": "0.jpg", "height": 720, "width": 960}

# img_id=0
# anno_id=0

#check if results directory exists, else create it
if not os.path.exists(resultspath):
  os.makedirs(resultspath)


imgPaths = os.listdir(pathtoimage)
print(imgPaths)

i=0

for imgPath in imgPaths:
  print(f"Processing image: {imgPath}")
  img = imutils.resize((cv2.imread(f"{pathtoimage}/{imgPath}")), width=640)
  if img is None:
    continue
  
  pic = remove_background_biggest_contour(img)
  result= remove_green_background(pic)
  extreme_points = find_extreme_points(pic)
  
  
  #results = model(img)
  #results = model(pathtoimage+'/'+imgPath)

  image_bboxes = []
  xywh = []

  #Get yolo results
  #for *xyxy, conf, cls in results.pandas().xyxy[0].itertuples(index=False):
    #run for each detection
  ran_sam = False
  pading = 8
  
  #image_bbox = (np.array([xyxy[0], xyxy[1], xyxy[2], xyxy[3]]))
  try:
    max_x=max(extreme_points[0][0],extreme_points[1][0],extreme_points[2][0],extreme_points[3][0]) +pading #-
    max_y=max(extreme_points[0][1],extreme_points[1][1],extreme_points[2][1],extreme_points[3][1])+pading
    min_y=min(extreme_points[0][1],extreme_points[1][1],extreme_points[2][1],extreme_points[3][1])-pading #-
    min_x=min(extreme_points[0][0],extreme_points[1][0],extreme_points[2][0],extreme_points[3][0])-pading
    bbox = extreme_points[0][0]+pading, extreme_points[0][1]-pading, extreme_points[1][0]+pading, extreme_points[1][1]-pading
  except:
    continue
  # w=extreme_points[0][1]+pading - extreme_points[0][0]+pading
  # h=extreme_points[1][0]+pading-extreme_points[0][0]+pading
  # print(x,y,w,h)
  
  #image_bbox = (np.array([xyxy[0], xyxy[1], xyxy[2], xyxy[3]]))
  if max_x <0 or max_y <0 or min_y <0 or min_x <0:
    continue
  
  xywh = (np.array([min_x, min_y, max_x-min_x, max_y-min_y]))
  
  if xywh[2] < 0 or xywh[3] < 0:
    continue
  
  if xywh[2] < 100 or xywh[3] < 100:
    continue
  sam_bounding_box = (np.array([min_x, min_y, max_x, max_y]))
  print(xywh)
  bb = (np.array([min_x, min_y, max_x, min_y]))
  image_bbox = (np.array([bbox[0], bbox[1], bbox[2], bbox[3]]))
  #draw the image bbox on the image and write it
  #image_bb=cv2.rectangle(img, (int(max_x), int(max_y)), (int(min_x), int(min_y)), (0, 255, 0), 2)
  #cv2.imwrite(f"{resultspath}/{imgPath[:-4]}_bb.png", image_bb)
  print(image_bbox)
  #xywh = [xyxy[0], xyxy[1], xyxy[2]-xyxy[0], xyxy[3]-xyxy[1]]
  
  #xywh = extreme_points[0], extreme_points[1], extreme_points[2]-extreme_points[0] , extreme_points[3]-extreme_points[0]


  #run sam
  if ran_sam == False:
    predictor.set_image(img)
    ran_sam = True

  mask, _, _ = predictor.predict(
      point_coords=None,
      point_labels=None,
      box=sam_bounding_box,
      multimask_output=False,
  )

  contours, _ = cv2.findContours(mask[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Your call to find the contours
  # threshold input image using otsu thresholding as mask and refine with morphology
  ret, pngmask = cv2.threshold(mask[0].astype(np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
  # save the mask 
  #cv2.imwrite(f"{resultspath}/{cutobject}_{i}_mask.png", pngmask)
  kernel = np.ones((9,9), np.uint8)
  pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)
  pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)

  # put mask into alpha channel of result
  result = img.copy()
  result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)
  # keep only the image that is within the mask
  result = cv2.bitwise_and(result, result, mask=pngmask)
  #cv2.imwrite(f"{resultspath}/{cutobject}_{i}.png", result)
  #to save with same name as original file
  # if already exists, save with _1, _2, etc
  if os.path.exists(f"{resultspath}/{imgPath[:-4]}.png"):
    if os.path.exists(f"{resultspath}/{imgPath[:-4]}_1.png"):
      print("File already exists, saving with _2")
      cv2.imwrite(f"{resultspath}/{imgPath[:-4]}_2.png", result)
    print("File already exists, saving with _1")
    cv2.imwrite(f"{resultspath}/{imgPath[:-4]}_1.png", result)

  cv2.imwrite(f"{resultspath}/{imgPath[:-4]}.png", result)
  i=i+1
ran_sam = False
