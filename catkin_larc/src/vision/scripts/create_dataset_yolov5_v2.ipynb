{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter\n",
    "from pycocotools import mask\n",
    "import json\n",
    "import yaml\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the three folders containing the images\n",
    "datasetPath = \"/home/jabv/Desktop/DS_letras_cropped\"\n",
    "fg_folders = [\n",
    "    (f\"{datasetPath}/A/\",\"A\" ),\n",
    "    (f\"{datasetPath}/B/\",\"B\" ),\n",
    "    (f\"{datasetPath}/C/\",\"C\" ),\n",
    "    (f\"{datasetPath}/D/\",\"D\" ),\n",
    "    (f\"{datasetPath}/E/\",\"E\" ),\n",
    "    (f\"{datasetPath}/F/\",\"F\" ),\n",
    "    (f\"{datasetPath}/G/\",\"G\" ),\n",
    "    (f\"{datasetPath}/H/\",\"H\" ),\n",
    "    (f\"{datasetPath}/I/\",\"I\" ),\n",
    "    (f\"{datasetPath}/verde/\",\"verde\" ),\n",
    "    (f\"{datasetPath}/azul/\",\"azul\" ),\n",
    "    (f\"{datasetPath}/amarillo/\",\"amarillo\" ),\n",
    "    (f\"{datasetPath}/rojo/\",\"rojo\" )\n",
    "]\n",
    "bg_folder = \"/home/jabv/Desktop/bg_imgs/\"\n",
    "output_folder = \"/home/jabv/Desktop/DS_letras/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'verde': 9, 'azul': 10, 'amarillo': 11, 'rojo': 12}\n",
      "[{'id': 0, 'name': 'A'}, {'id': 1, 'name': 'B'}, {'id': 2, 'name': 'C'}, {'id': 3, 'name': 'D'}, {'id': 4, 'name': 'E'}, {'id': 5, 'name': 'F'}, {'id': 6, 'name': 'G'}, {'id': 7, 'name': 'H'}, {'id': 8, 'name': 'I'}, {'id': 9, 'name': 'verde'}, {'id': 10, 'name': 'azul'}, {'id': 11, 'name': 'amarillo'}, {'id': 12, 'name': 'rojo'}]\n"
     ]
    }
   ],
   "source": [
    "objects_list = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"verde\", \"azul\", \"amarillo\", \"rojo\"]\n",
    "annotations_ID = {}\n",
    "categories = []\n",
    "for i, object in enumerate(objects_list):\n",
    "    annotations_ID[object] = i\n",
    "    categories.append({\"id\": i, \"name\": object})\n",
    "\n",
    "print(annotations_ID)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of files in each of the three folders\n",
    "fg_files = {}\n",
    "for folder, category in fg_folders:\n",
    "    fg_files[category] = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(output_folder)\n",
    "trainfolder = output_folder + \"train/\"\n",
    "testfolder = output_folder + \"test/\"\n",
    "validfolder = output_folder + \"valid/\"\n",
    "os.mkdir(trainfolder)\n",
    "os.mkdir(testfolder)\n",
    "os.mkdir(validfolder)\n",
    "os.mkdir(trainfolder + \"images/\")\n",
    "os.mkdir(trainfolder + \"labels/\")\n",
    "os.mkdir(testfolder + \"images/\")\n",
    "os.mkdir(testfolder + \"labels/\")\n",
    "os.mkdir(validfolder + \"images/\")\n",
    "os.mkdir(validfolder + \"labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "annotations=[]\n",
    "annotations2=[]\n",
    "annot_csv=[]\n",
    "\n",
    "img_id=int(0)\n",
    "anno_id=int(0)\n",
    "\n",
    "rescaling_min = 0.20\n",
    "rescaling_max = 0.70\n",
    "\n",
    "# Ratios at which these values will be modified\n",
    "brightness_ratio = 0.05\n",
    "saturation_ratio = 0.05\n",
    "hue_ratio = 0.02\n",
    "\n",
    "for j in range(20000):\n",
    "    #create empty label file\n",
    "    with open(f'{trainfolder}labels/{img_id}.txt', 'w') as file:\n",
    "        pass\n",
    "    #select hramdomly how many objects will be in an image\n",
    "    num_objects = random.randint(0, 5)\n",
    "    #print(\"number of objects\",num_objects)\n",
    "    # Select random foreground images from the three folders, with replacement\n",
    "    fg_categories = random.choices(objects_list, k=num_objects)\n",
    "    \n",
    "    fg_files_selected = []\n",
    "    for category in fg_categories:\n",
    "        fg_files_selected.append([category,random.choice(fg_files[category])])\n",
    "    #print(\"seleccion\",fg_files_selected)\n",
    "    # Load the selected foreground images using Pillow\n",
    "    fg_imgs = []\n",
    "    for img in fg_files_selected:\n",
    "        folder = [f[0] for f in fg_folders if f[1] == img[0]][0]\n",
    "        fg_imgs.append([img[0],Image.open(folder + img[1]),folder+img[1]])\n",
    "\n",
    "    # Randomly resize and rotate the foreground images using Pillow's transform module\n",
    "    # img[0] is category, img[1] is image, img[2] is path\n",
    "    for img in fg_imgs:\n",
    "        fg_img=img[1]\n",
    "        angle = random.randint(-5, 5)\n",
    "        scale = random.uniform(rescaling_min, rescaling_max)\n",
    "        fg_img = fg_img.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
    "        fg_img = fg_img.resize((int(fg_img.width * scale), int(fg_img.height * scale)))\n",
    "        fg_img = ImageEnhance.Brightness(fg_img).enhance(random.uniform(0.7, 1.3))\n",
    "        fg_img = ImageEnhance.Contrast(fg_img).enhance(random.uniform(0.9, 1.1))\n",
    "        fg_img = ImageEnhance.Color(fg_img).enhance(random.uniform(0.7, 1.3))\n",
    "        fg_img = fg_img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.0, 0.5)))\n",
    "\n",
    "\n",
    "        img[1] = fg_img\n",
    "\n",
    "    # Load the background image using Pillow\n",
    "    bg_files = os.listdir(bg_folder)\n",
    "    bg_file = random.choice(bg_files)\n",
    "    bg_img = Image.open(bg_folder + bg_file)\n",
    "\n",
    "    # Define the maximum overlap as a percentage\n",
    "    max_overlap_pct = 10\n",
    "\n",
    "    # Define an array to keep track of occupied areas\n",
    "    occupied = np.zeros((bg_img.height, bg_img.width))\n",
    "\n",
    "    for img in fg_imgs:\n",
    "        fg_img=img[1]\n",
    "\n",
    "        # Calculate the maximum overlap area\n",
    "        max_overlap_area = (fg_img.width * fg_img.height)\n",
    "\n",
    "        seg_img = img[1]\n",
    "\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        img_arr = np.array(seg_img)\n",
    "        # Create a binary mask of the non-transparent pixels\n",
    "        mask = img_arr[:, :, 3] != 0\n",
    "\n",
    "        # Convert the mask to a COCO format segmentation\n",
    "        segmentation = []\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                if mask[i, j]:\n",
    "                    segmentation.append(j)\n",
    "                    segmentation.append(i)\n",
    "        segmentation = [segmentation]\n",
    "\n",
    "        # Calculate the area of the segmentation\n",
    "        area = 0\n",
    "        for i in range(len(segmentation[0]) // 2):\n",
    "            x1 = segmentation[0][2 * i]\n",
    "            y1 = segmentation[0][2 * i + 1]\n",
    "            x2 = segmentation[0][(2 * i + 2) % len(segmentation[0])]\n",
    "            y2 = segmentation[0][(2 * i + 3) % len(segmentation[0])]\n",
    "            area += x1 * y2 - x2 * y1\n",
    "        area = abs(area) / 2\n",
    "        \n",
    "        # Draw the segmentation onto a copy of the original image\n",
    "        #image_copy = image.copy()\n",
    "        #cv2.fillPoly(image_copy, aux_segmentation, color=(0, 255, 0))\n",
    "\n",
    "        # Display the image with segmentation overlay\n",
    "        #cv2.imshow('Image with Segmentation', image_copy)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "        # Calculate the maximum allowed position for the top-left corner\n",
    "        max_x = bg_img.width - fg_img.width\n",
    "        max_y = bg_img.height - fg_img.height\n",
    "        area = fg_img.width * fg_img.height\n",
    "\n",
    "        # Generate a random location until an unoccupied area is found that meets the overlap limit\n",
    "        total_area = bg_img.width * bg_img.height\n",
    "        overlap_area = total_area\n",
    "        \n",
    "        while overlap_area / area > max_overlap_pct / 100:\n",
    "            try:\n",
    "                x = random.randint(0, max_x)\n",
    "                y = random.randint(0, max_y)\n",
    "            except:\n",
    "                x = random.randint(0, abs(max_x))\n",
    "                y = random.randint(0, abs(max_y))\n",
    "\n",
    "            # Calculate the overlap area\n",
    "            overlap_area = np.sum(occupied[y:y+fg_img.height, x:x+fg_img.width])\n",
    "\n",
    "            # Check if the area is unoccupied and the overlap limit is not exceeded\n",
    "            if (max_overlap_area) >= overlap_area/10:\n",
    "                break\n",
    "            if i==10:\n",
    "                continue\n",
    "        \n",
    "        for i in range(0, len(segmentation[0])):\n",
    "            if i % 2:\n",
    "                segmentation[0][i]=int(segmentation[0][i]+y)\n",
    "            else :\n",
    "                segmentation[0][i]=int(segmentation[0][i]+x)\n",
    "        # Update the occupied array\n",
    "        occupied[y:y+fg_img.height, x:x+fg_img.width] = 1\n",
    "\n",
    "        bg_img.paste(fg_img, (x, y), fg_img)\n",
    "        x_center_ann = (x+fg_img.width/2) / bg_img.width\n",
    "        y_center_ann = (y+fg_img.height/2) / bg_img.height\n",
    "        width_ann = fg_img.width / bg_img.width\n",
    "        height_ann = fg_img.height / bg_img.height\n",
    "        with open(f'{trainfolder}labels/{img_id}.txt', 'a') as f:\n",
    "            f.write(f\"{annotations_ID[img[0]]} {x_center_ann} {y_center_ann} {width_ann} {height_ann}\\n\")\n",
    "        annotations2.append({\"id\": anno_id,\"image_id\": img_id,\"category_id\": annotations_ID[img[0]],\"bbox\": [x, y, fg_img.width, fg_img.height],\"segmentation\": segmentation,\"area\": area,\"iscrowd\": 0})\n",
    "        annotations.append({\"id\": anno_id,\"image_id\": img_id,\"category_id\": annotations_ID[img[0]],\"bbox\": [x, y, fg_img.width, fg_img.height],\"segmentation\": [],\"area\": fg_img.height*fg_img.width,\"iscrowd\": 0})\n",
    "        annot_csv.append([\"TRAIN\", output_folder + str(img_id)+\".jpg\", img[0], x/bg_img.width, y/bg_img.height,\"\",\"\",(x+fg_img.width)/bg_img.width, (y+fg_img.height)/bg_img.height])\n",
    "        anno_id=anno_id+1\n",
    "        #draw = ImageDraw.Draw(bg_img)\n",
    "        #fdraw.rectangle((x, y, x+fg_img.width, y+fg_img.height), outline='red', width=3)\n",
    "    bg_img.save(f\"{trainfolder}images/\"+str(img_id)+\".jpg\", quality=100)\n",
    "    images.append({\"id\": img_id, \"file_name\": str(img_id)+\".jpg\",\"height\": bg_img.height,\"width\": bg_img.width})\n",
    "    img_id=img_id+1\n",
    "    #print(img_id)\n",
    "\n",
    "#making data.yaml\n",
    "data = dict(\n",
    "    train = f\"{trainfolder}images\",\n",
    "    val = f\"{validfolder}images\",\n",
    "    test = f\"{validfolder}images\",\n",
    "    nc = len(annotations_ID),\n",
    "    names = list(annotations_ID.keys())\n",
    "    )\n",
    "#storing\n",
    "with open(f'{output_folder}data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ARTIR DE AQUI NO\n",
    "# write csv file with annot_csv\n",
    "with open(f'{output_folder}/annotations_val.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(annot_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the COCO dictionary\n",
    "coco_dict = {\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations,\n",
    "    \"categories\": categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dict2 = {\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations2,\n",
    "    \"categories\": categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dict2\n",
    "# Convert the dictionary to a JSON string\n",
    "json_string = json.dumps(coco_dict2)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open(f\"{output_folder}annotations_val_seg.json\", 'w') as f:\n",
    "    f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dict\n",
    "# Convert the dictionary to a JSON string\n",
    "json_string = json.dumps(coco_dict)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open(f\"{output_folder}annotations_val.json\", 'w') as f:\n",
    "    f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
